name: Deploy Infrastructure

on:
  push:
    #branches: ["main"]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.ref == 'refs/heads/main' && 'prod' || 'dev' }}

    env:
      TF_VAR_project_id: ${{ env. }}
      TF_VAR_sa_email: ${{ secrets.TERRAFORM_SERVICE_ACCOUNT_EMAIL }}
      TF_VAR_region: "europe-west9"
      TF_STATE_BUCKET: "${{ env.PROJECT_ID }}-tf-state"
      TF_STATE_PREFIX: "data-analytics-platform-event-driven"

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Install zip & Zip code
        run: |
          sudo apt-get update
          sudo apt-get install zip -y
          zip ../infra/function-source.zip main.py requirements.txt
          ls -la ../infra/
        working-directory: code

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.3.9

      - name: Authenticate with Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GOOGLE_CREDENTIALS }}

      - name: Terraform Init
        run: |
          terraform init \
            -reconfigure \
            -backend-config="bucket=${TF_STATE_BUCKET}" \
            -backend-config="prefix=${TF_STATE_PREFIX}"
        working-directory: infra

      - name: Import Existing Resources
        run: |
          # Import BigQuery dataset ecommerce if not already in state
          if ! terraform state list | grep -q "google_bigquery_dataset.ecommerce"; then
            if bq ls --project_id=$TF_VAR_project_id | grep -q "ecommerce"; then
              echo "Dataset ecommerce exists but not in state, importing..."
              terraform import google_bigquery_dataset.ecommerce projects/$TF_VAR_project_id/datasets/ecommerce
            else
              echo "Dataset ecommerce does not exist, will be created by Terraform."
            fi
          else
            echo "Dataset ecommerce is already managed by Terraform, skipping import."
          fi

          # Import BigQuery table order_events if not already in state
          if ! terraform state list | grep -q "google_bigquery_table.order_events"; then
            if bq show --format=prettyjson $TF_VAR_project_id:ecommerce.order_events > /dev/null 2>&1; then
              echo "BigQuery table order_events exists but not in state, importing..."
              terraform import google_bigquery_table.order_events projects/$TF_VAR_project_id/datasets/ecommerce/tables/order_events
            else
              echo "BigQuery table order_events does not exist, will be created by Terraform."
            fi
          else
            echo "BigQuery table order_events is already managed by Terraform, skipping import."
          fi

          # Import Service Account if not already in state
          if ! terraform state list | grep -q "google_service_account.function_sa"; then
            terraform import google_service_account.function_sa projects/$TF_VAR_project_id/serviceAccounts/gcs-to-bq-trigger@$TF_VAR_project_id.iam.gserviceaccount.com || true
          else
            echo "Service account function_sa is already managed by Terraform, skipping import."
          fi

          # Import Storage Buckets if not already in state
          if ! terraform state list | grep -q "google_storage_bucket.gcf_source_bucket"; then
            terraform import google_storage_bucket.gcf_source_bucket ${TF_VAR_project_id}-gcf-source-bucket || true
          else
            echo "Bucket gcf_source_bucket is already managed by Terraform, skipping import."
          fi

          if ! terraform state list | grep -q "google_storage_bucket.upload_bucket"; then
            terraform import google_storage_bucket.upload_bucket ${TF_VAR_project_id}-upload || true
          else
            echo "Bucket upload_bucket is already managed by Terraform, skipping import."
          fi

          if ! terraform state list | grep -q "google_storage_bucket.archive_bucket"; then
            terraform import google_storage_bucket.archive_bucket ${TF_VAR_project_id}-archive || true
          else
            echo "Bucket archive_bucket is already managed by Terraform, skipping import."
          fi
        working-directory: infra

      - name: Verify Terraform State
        run: terraform state list
        working-directory: infra

      - name: Terraform Plan
        run: terraform plan -out=tfplan
        working-directory: infra

      - name: Terraform Apply
        run: terraform apply -auto-approve tfplan
        working-directory: infra