name: Deploy Infrastructure

on:
  push:
    #branches: ["main"]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.ref == 'refs/heads/main' && 'prod' || 'dev' }}

    env:
      TF_VAR_project_id: ${{ vars.PROJECT_ID }}
      TF_VAR_sa_email: ${{ vars.TERRAFORM_SERVICE_ACCOUNT_EMAIL }}
      TF_VAR_region: "europe-west9"
      TF_STATE_BUCKET: "${{ vars.PROJECT_ID }}-tf-state"
      TF_STATE_PREFIX: "data-analytics-platform-event-driven"

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Install zip & Zip code
        run: |
          sudo apt-get update
          sudo apt-get install zip -y
          zip -r ../infra/function-source.zip .
          ls -la ../infra/
        working-directory: etl_pipeline

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.3.9

      - name: Authenticate with Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GOOGLE_CREDENTIALS }}

      - name: Terraform Init
        run: |
          terraform init \
            -reconfigure \
            -backend-config="bucket=${TF_STATE_BUCKET}" \
            -backend-config="prefix=${TF_STATE_PREFIX}"
        working-directory: infra

      - name: Import Existing Resources
        run: |
          # 1. Import BigQuery dataset surveys if not already in state
          if ! terraform state list | grep -q "google_bigquery_dataset.surveys"; then
            if bq ls --project_id=$TF_VAR_project_id | grep -q "surveys"; then
              echo "Dataset surveys exists but not in state, importing..."
              terraform import google_bigquery_dataset.surveys projects/$TF_VAR_project_id/datasets/surveys
            else
              echo "Dataset surveys does not exist, will be created by Terraform."
            fi
          else
            echo "Dataset surveys is already managed by Terraform, skipping import."
          fi

          # 2. Import BigQuery table developer_salaries if not already in state
          if ! terraform state list | grep -q "google_bigquery_table.developer_salaries"; then
            if bq show --format=prettyjson $TF_VAR_project_id:surveys.developer_salaries > /dev/null 2>&1; then
              echo "BigQuery table developer_salaries exists but not in state, importing..."
              terraform import google_bigquery_table.developer_salaries projects/$TF_VAR_project_id/datasets/surveys/tables/developer_salaries
            else
              echo "BigQuery table developer_salaries does not exist, will be created by Terraform."
            fi
          else
            echo "BigQuery table developer_salaries is already managed by Terraform, skipping import."
          fi

          # 3. Import Service Account if not already in state
          if ! terraform state list | grep -q "google_service_account.function_sa"; then
            if gcloud iam service-accounts describe gcs-to-bq-trigger@$TF_VAR_project_id.iam.gserviceaccount.com --project=$TF_VAR_project_id > /dev/null 2>&1; then
              echo "Service account gcs-to-bq-trigger exists but not in state, importing..."
              terraform import google_service_account.function_sa projects/$TF_VAR_project_id/serviceAccounts/gcs-to-bq-trigger@$TF_VAR_project_id.iam.gserviceaccount.com
            else
              echo "Service account gcs-to-bq-trigger does not exist, will be created by Terraform."
            fi
          else
            echo "Service account function_sa is already managed by Terraform, skipping import."
          fi

          # 4. Import Storage Buckets if not already in state
          if ! terraform state list | grep -q "google_storage_bucket.gcf_source_bucket"; then
            if gsutil ls gs://${TF_VAR_project_id}-gcf-source-bucket > /dev/null 2>&1; then
              echo "Bucket ${TF_VAR_project_id}-gcf-source-bucket exists but not in state, importing..."
              terraform import google_storage_bucket.gcf_source_bucket ${TF_VAR_project_id}-gcf-source-bucket
            else
              echo "Bucket ${TF_VAR_project_id}-gcf-source-bucket does not exist, will be created by Terraform."
            fi
          else
            echo "Bucket gcf_source_bucket is already managed by Terraform, skipping import."
          fi

          if ! terraform state list | grep -q "google_storage_bucket.upload_bucket"; then
            if gsutil ls gs://${TF_VAR_project_id}-upload > /dev/null 2>&1; then
              echo "Bucket ${TF_VAR_project_id}-upload exists but not in state, importing..."
              terraform import google_storage_bucket.upload_bucket ${TF_VAR_project_id}-upload
            else
              echo "Bucket ${TF_VAR_project_id}-upload does not exist, will be created by Terraform."
            fi
          else
            echo "Bucket upload_bucket is already managed by Terraform, skipping import."
          fi

          if ! terraform state list | grep -q "google_storage_bucket.archive_bucket"; then
            if gsutil ls gs://${TF_VAR_project_id}-archive > /dev/null 2>&1; then
              echo "Bucket ${TF_VAR_project_id}-archive exists but not in state, importing..."
              terraform import google_storage_bucket.archive_bucket ${TF_VAR_project_id}-archive
            else
              echo "Bucket ${TF_VAR_project_id}-archive does not exist, will be created by Terraform."
            fi
          else
            echo "Bucket archive_bucket is already managed by Terraform, skipping import."
          fi
        working-directory: infra

      - name: Verify Terraform State
        run: terraform state list
        working-directory: infra

      - name: Terraform Plan
        run: terraform plan -out=tfplan
        working-directory: infra

      - name: Terraform Apply
        run: terraform apply -auto-approve tfplan
        working-directory: infra